{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## การดึงข้อมูลจากอินเทอร์เน็ตโดยใช้ python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.getcwd() #Get Current Directory Path\n",
    "#os.chdir() #Change Directory Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Reading File (10 mins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ไฟล์มาตราฐานที่เราพบบ่อยคือ csv, json และ xml นอกจากนี้ยังมี Shapefile file, Image file สามารถดูวิธีการอ่านไฟล์ชนิดต่างๆ ได้จาก official document ของ pandas\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/io.html\n",
    "\n",
    "ในส่วนนี้เราจะใช้ตัวอย่างข้อมูลเปิดเผยของไทยจาก \n",
    "\n",
    "https://data.go.th/\n",
    "\n",
    "\n",
    "#### 1.1. Comma-Separated Values: CSV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = \"https://data.go.th/dataset/8a956917-436d-4afd-a2d4-59e4dd8e906e/resource/894664f5-447a-46ec-9fe2-1b6ae8f18be5/download/confirmed-cases-since-120465.csv\"\n",
    "pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. JavaScript Object Notation: JSON\n",
    "\n",
    "ตัวอย่าง JSON File\n",
    "![convert notebook to web app](https://media.geeksforgeeks.org/wp-content/uploads/20210708215022/simplejsonex.png)\n",
    "\n",
    "ตัวอย่าง JSON File แบบ Nested\n",
    "![convert notebook to web app](https://media.geeksforgeeks.org/wp-content/uploads/20210708215250/nestedjsonex.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://data.go.th/dataset/typepro\n",
    "url = \"https://data.go.th/dataset/607f1193-5a6c-4a2f-83e3-0f1ae79a9909/resource/9dc9e063-9ca6-46a6-b664-a63e3ad5b022/download/typepro.json\"\n",
    "pd.read_json(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Extensible Markup Language: XML   (Optional)\n",
    "\n",
    "\n",
    "#### 1.4. Image: JPEG, ESP, PNG  (Optional)\n",
    "\n",
    "\n",
    "#### 1.5. Shapefile Shape Format: SHP  (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Web Scraping (40 mins)\n",
    "\n",
    "เราสามารถแบ่งประเภทของเว็ปหลักๆได้คือ\n",
    "\n",
    "- Static คือ เว็ปไซด์ที่โครงสร้างไม่เปลี่ยนแปลงเมื่อเราเปิดหน้าเว็ปขึ้นมา เราจะใช้ bs4 ในการ Scrap \n",
    "\n",
    "- Dynamic คือ เว็ปไซด์ที่โครงสร้างเปลี่ยนแปลง อาจจะเปลี่ยนแปรงโดยัตโนมัติหรือเกิดสั่งการจากผู้ใช้ ในกรณีนี้เราจะไม่สามารถใช้ bs4 ในการ Scrap จึงต้องเปลี่ยนไปใช้ Diver Remote Control จาก Selenium\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### การเข้าถึงโครงสร้าง HTML ขอเว็ปผ่าน Chrome Developer\n",
    "\n",
    "1. เปิด Chorme ไปที่หน้าเว็ปที่ต้องการ\n",
    "2. คลิกขวาแล้วเลือก Inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### องค์ประกอบของ Element ใน HTML \n",
    "\n",
    "\n",
    "![convert notebook to web app](https://4.bp.blogspot.com/-B5vUzJXNAoE/Vuay2ygsN2I/AAAAAAAAG5o/-qOAVBa3LRkJ0fPWywYzkAcmezRAY2Rxg/s1600/html-syntax.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. คำสั่งที่ใช้บ่อยในการ bs4\n",
    "\n",
    "##### คำสั่งที่ใช้บ่อยในการค้นหา\n",
    "\n",
    "**find_all(name, attrs, recursive, string, limit)**\n",
    "\n",
    "- name สั่งค้นหาโดยชื่อ tag เช่น \"a\", \"a div\", [\"a\",\"div\"]\n",
    "- attrs สั่งค้นหาโดยชื่อ CSS class เช่น \"title\", {\"class\":\"class of your target a element\"}, class_=\"sister\"\n",
    "- recursive สั่งค้นหาในเลเยอร์ต้นไม้\n",
    "- string สั่งค้นหาโดยระบุคำเฉพาะ\n",
    "- limit สั่งจำกัดจำนวน line code ที่ค้นพบ\n",
    "\n",
    "**.get(attrs)**\n",
    "- คืนค่า value ใน attr ที่กำหนด\n",
    "\n",
    "**.text**\n",
    "- คืนค่า content ที่เป็นข้อความ\n",
    "\n",
    "##### คำสั่งในการดึงข้อมูลแบบตาราง\n",
    "\n",
    "**pd.read_html(URL)**\n",
    "\n",
    "\n",
    "##### คำสั่งในการ save file\n",
    "\n",
    "**open(name of file, 'wb').write(req data)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ตัวอย่างที่ 1. ดึงข้อมูลข้อความจาก Wiki "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://en.wikipedia.org/wiki/Mathematics' #url ของ web ที่สนใจ\n",
    "req = requests.get(url).content #ส่งคำขอแบบ GET เพื่อดึงข้อมูลผ่าน Network และเลือกเฉพาะส่วนของข้อมูล\n",
    "soup = BeautifulSoup(req, 'html.parser') #ใช้ bs เพื่ออ่านภาษา HTML\n",
    "#print(soup.prettify()) #แสดงผล HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#หา title ใน text\n",
    "atag = soup.find_all(\"a\") \n",
    "titleatag = [x.get(\"title\") for x in atag]\n",
    "titleatag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#หา link ใน text\n",
    "atag = soup.find_all(\"a\") \n",
    "hrefatag = [x.get(\"href\") for x in atag]\n",
    "hrefatag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#หา link ของรูปภาพ\n",
    "imgtag = soup.find_all(\"img\")\n",
    "imgsrc = [x.get(\"src\") for x in imgtag]\n",
    "imgsrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#การ save file\n",
    "name = \"https://upload.wikimedia.org/wikipedia/commons/2/23/Image-Al-Kit%C4%81b_al-mu%E1%B8%ABta%E1%B9%A3ar_f%C4%AB_%E1%B8%A5is%C4%81b_al-%C4%9Fabr_wa-l-muq%C4%81bala.jpg\"\n",
    "req = requests.get(name)\n",
    "open(\"image.jpg\", \"wb\").write(req.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.text #สกัดข้อมูลเฉพาะส่วนของ Text ทั้งหมด"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ตัวอย่างที่ 2. ดึงข้อมูลบริษัทจากตลาดหลักทรัพย์"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# ข้อมูลจากเว็ป https://portal.set.or.th/mai/stockslookup.do\n",
    "\n",
    "engletter = ['NUMBER'] + [x for x in string.ascii_uppercase[:5]] #สร้างลิสท์ตัวอักษรภาษาอังกฤษ\n",
    "#print(engletter)\n",
    "\n",
    "CompanyTable = pd.DataFrame() #สร้าง DataFrame เปล่า\n",
    "\n",
    "for i in engletter: #รันหน้า URL เพื่อเก็บขอ้อมูลในตารางแต่ละหน้า\n",
    "    url = 'https://portal.set.or.th/mai/stockslookup.do?type=S&prefix={}'.format(i) #สร้างชื่อ URL โดยเปลี่ยน prefix \n",
    "    pdtab = pd.read_html(url)[0] #ดึงข้อมูลในตาราง\n",
    "    CompanyTable = pd.concat([CompanyTable, pdtab]) #ต่อตารางในแต่ละรอบ\n",
    "    time.sleep(2) # หยุดรัน 2 วินาที ป้องกันการดึงข้อมูลเร็วเกินไปซึ่งอาจจะทำให้ IP โดน Block\n",
    "\n",
    "#CompanyTable.to_csv(\"SETCompanies.csv\") #Save ตารางใน File CSV\n",
    "\n",
    "print(CompanyTable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ตัวอย่างที่ 3. ดึงข้อมูล สส. และรูปภาพสำหรับการเลือกตั้ง 2566"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.vote62.com/candidates/%e0%b8%aa.%e0%b8%aa.%e0%b8%9a%e0%b8%b1%e0%b8%8d%e0%b8%8a%e0%b8%b5%e0%b8%a3%e0%b8%b2%e0%b8%a2%e0%b8%8a%e0%b8%b7%e0%b9%88%e0%b8%ad/\n",
    "#Save Logo พรรค\n",
    "\n",
    "url = 'https://www.vote62.com/candidates/%e0%b8%aa.%e0%b8%aa.%e0%b8%9a%e0%b8%b1%e0%b8%8d%e0%b8%8a%e0%b8%b5%e0%b8%a3%e0%b8%b2%e0%b8%a2%e0%b8%8a%e0%b8%b7%e0%b9%88%e0%b8%ad/' #url ของ web ที่สนใจ\n",
    "req = requests.get(url).content #ส่งคำขอแบบ GET เพื่อดึงข้อมูลผ่าน Network และเลือกเฉพาะส่วนของข้อมูล\n",
    "soup = BeautifulSoup(req, 'html.parser') #ใช้ bs เพื่ออ่านภาษา HTML\n",
    "#หา link ของรูปภาพ \n",
    "imgtag = soup.find_all(\"img\", {\"class\":\"⭐️di6wof-6 w-14 h-14\"})\n",
    "#imgtag \n",
    "imgsrc = [x.get(\"src\") for x in imgtag]\n",
    "imgname = [x.get(\"alt\") for x in imgtag]\n",
    "fulllink = [\"https://www.vote62.com\" + str(x) for x in imgsrc] \n",
    "\n",
    "\n",
    "for i in range(len(fulllink)):\n",
    "    req = requests.get(fulllink[i])\n",
    "    open(str(imgname[i]) + \".png\", \"wb\").write(req.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ดึงข้อมูลรายชื่อผู้สมัครแต่ละพรรค\n",
    "\n",
    "url = 'https://www.vote62.com/candidates/%e0%b8%aa.%e0%b8%aa.%e0%b8%9a%e0%b8%b1%e0%b8%8d%e0%b8%8a%e0%b8%b5%e0%b8%a3%e0%b8%b2%e0%b8%a2%e0%b8%8a%e0%b8%b7%e0%b9%88%e0%b8%ad/'\n",
    "req = requests.get(url).content #ส่งคำขอแบบ GET เพื่อดึงข้อมูลผ่าน Network และเลือกเฉพาะส่วนของข้อมูล\n",
    "soup = BeautifulSoup(req, 'html.parser') #ใช้ bs เพื่ออ่านภาษา HTML\n",
    "\n",
    "partylink = soup.find_all(\"ul\", {\"class\":\"⭐️di6wof-6 relative grid sm:grid-cols-2 md:grid-cols-2 lg:grid-cols-3 xl:grid-cols-3 gap-3.5 lg:gap-5 z-0\"})\n",
    "partylink = partylink[0].find_all(\"a\")\n",
    "link = [x.get('href') for x in partylink]\n",
    "\n",
    "partylist = pd.DataFrame()\n",
    "for i in link:\n",
    "    req = requests.get(\"https://www.vote62.com\" + str(i)).content\n",
    "    soup = BeautifulSoup(req, 'html.parser') \n",
    "    num = soup.find(\"span\", {\"class\":\"text-xl font-extrabold leading-none\"}).text \n",
    "    name = soup.find(\"h2\", {\"text-xl font-extrabold\"}).text\n",
    "    listtag = soup.find_all(\"h4\", {\"class\":\"text-md font-extrabold truncate\"})\n",
    "    candiname = [x.text for x in listtag]\n",
    "    partylist = pd.concat([partylist, pd.DataFrame({'เบอร์': [num]*len(candiname), 'พรรค': [name]*len(candiname), 'รายชื่อ': candiname})])\n",
    "    time.sleep(2)\n",
    "#partylist.to_csv(\"Partylist.csv\") #Save ตารางใน File CSV\n",
    "\n",
    "print(partylist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Application Programming Interface: API (40 mins)\n",
    "\n",
    "ในที่นี้เราจะใช้แค่ RESTful เนื่องจากเป็น API method ที่ใช้ทั่วไป เราอาจะคุ้นเคยกับการสั่งอาหารโดยใช้ใรายการ การรับส่ง API ก็มีะบวนการคล้ายๆ กัน\n",
    "\n",
    "![convert notebook to web app](http://4.bp.blogspot.com/-qQOLFczR9SE/UE4T1f5ldkI/AAAAAAAAL1g/zx_rj-EK4MQ/s640/IMG_2664.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "วิธีการดึงข้อมูลจาก API มี 2 รูปแบบคือ GET และ POST โดยผู้ให้บริการจะกำหนดวิธีการส่งไว้ใน API document\n",
    "\n",
    "##### ส่วนต่างๆ ของการส่ง API\n",
    "\n",
    "- Hearder \n",
    "\n",
    "ส่วนหัวของ request มักจะใช้กรอก รหัส, Authorization, Caching , Cookies ซึ่งส่วนมาก API ที่เข้าถึงโดยไม่ต้องมีบัญชีจะไม่ต้องกรอกส่วนนี้\n",
    "\n",
    "- Body \n",
    "\n",
    "ส่วนนี้ใช้กรอก Parameter ของ request\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ตัวอย่างที่ 1 การดึงข้อมูลเหรียญคลิปโตจาก Binance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://binance-docs.github.io/apidocs/spot/en/\n",
    "\n",
    "#ดึงข้อมูล OHLC ของเหรียญ BNBBTC ความถี่ Trick \n",
    "\n",
    "url = 'https://api.binance.com/api/v3/klines'\n",
    "params = {'symbol':'BNBBTC',\n",
    "          'interval':'1s'}\n",
    "req = requests.get(url, params=params)\n",
    "#req.url\n",
    "#req.content\n",
    "#req = requests.get(url, params=params, cookies=cookies, headers=headers) # Full Request \n",
    "data = pd.read_json(req.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ตัวอย่างที่ 2 การดึงข้อมูลกระทรวงพานิชน์"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://data.moc.go.th/developer\n",
    "#ข้อมูลราคาสินค้าเกษตร\n",
    "#https://data.moc.go.th/OpenData/GISProductPrice\n",
    "\n",
    "url = 'https://dataapi.moc.go.th/gis-product-prices'\n",
    "params = {'product_id':'P11001',\n",
    "          'from_date':'2018-01-01',\n",
    "          'to_date':'2018-02-28'}\n",
    "req = requests.get(url, params=params)\n",
    "data = pd.read_json(req.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = data['price_list']\n",
    "Price = pd.DataFrame()\n",
    "for i in sdata:\n",
    "    Price = pd.concat([Price,pd.DataFrame(i, index=[0])])\n",
    "print(Price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ตัวอย่างที่ 3 การดึงข้อมูลจากธนาคารแห่งประเทศไทย"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ดึงข้อมูลผลิตภัณฑ์เงินฝาก\n",
    "#https://apiportal.bot.or.th/bot/public/node/6103\n",
    "\n",
    "headers = {\n",
    "    'X-IBM-Client-Id': \"REPLACE_THIS_KEY\",\n",
    "    'accept': \"application/json\"\n",
    "    }\n",
    "\n",
    "params = {\"FICodeList\":\"002\",\n",
    "          \"AccountTypeList\":\"1\",\n",
    "          \"BalanceAmount\":\"\",\n",
    "          \"ProductName\":\"\",\n",
    "          \"DepositTermRange\":\"\",\n",
    "          \"DepositTermType\":\"\",\n",
    "          \"InterestWithoutTax\":\"\",\n",
    "          \"AccntWithInsrnc\":\"\",\n",
    "          \"ProductRelate\":\"\"}\n",
    "\n",
    "req = requests.post(url, params=params, headers=headers)\n",
    "data = pd.read_json(req.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
